# Profile
I work as an Insurance Pricing Analyst and am currently doing a degree level apprenticeship in Data Science. I have worked in the Insurance industry for 25 years across multiple roles. For the last 14 years those roles have been in Analytical departments covering Personal Line Insurance and Application Fraud.

# Evolution of Analytical tools

When I first started in Analytical roles the Data I would work with was supplied by the centralised Data team, my team and I would use Excel to create basic charts and tables to demonstrate where pricing changes could be best placed. Shortly after I started we began to use the WTW software, Radar. This allowed us to use integrated rating tables to view prices for a batch of risks then apply changes and compare outputs.

Our need for data becamce more and the routinely updated tables from the central data team weren't going to be enough for all we wanted to see. At this point SAS started to be used to create our own tables and transform current tables to allow us to better analyse the data our organisation held.

After 4 years of this work I moved to Fraud, I was the first analyst in the application Fraud team and, as such, had to create all new reports from scratch. I greatly increased my SAS knowledge whilst working in this role and used both Data steps and Proc SQL coding to export and analyse data. Once I tried to export too much information from a live feed and froze a critical system for all users in the company. The central data team now export all files each night and analysts can access them the day after, this prevents the system from being frozen – I was not the only one to make this mistake.

A third party provider supplied a fraud database which was shared across the industry. I used the skills I had gained using proc SQL in SAS to access an SQL based query tool to interrogate this database and create improved reports for fraud.

One of my final acts in fraud was to use Excel Macros to create a tool for the fraud investigators where they could select from a range of options or select their own factors to create an output detailing risks which match the criteria selected. This helped to identify fraudulent policies based on current trends seen. This used User Forms and Macros from the VBA tools to make a user interface.

I began to look at some early Machine Learning modules as options to detect Fraud, but it wouldn’t be until I returned to pricing that I started to use some of these.

I returned to a pricing role after this and saw how the use of SAS had increased since I’d left. I started to use SAS coding to create development triangles. These display how a scheme performance changes over time with each underwriting year displayed by a separate line.

At this time Machine Learning was beginning to be investigated. My first experience of it was to create a Decision Tree using some pre-written R code and an Excel Macro enabled spreadsheet. Machine Learning models are still rarely used in the pricing teams, except for the newly formed Technical Pricing Team. I am trying to help spread the use of these, I ran a training session to talk another team through the process of running a Decision Tree and have now written a process guide on how this is done.

## Decision Tree

Below are links to the process guide, excel spreadsheet and R code required to create the decision tree.

<img class="rounded-circle" alt="Decision Tree Process Guide" src="/assests/Decision Tree Process.docx" />

## Data analysis

### Headings 3

# Image Subsection

<img class="rounded-circle" alt="example" src="/assests/Screenshot_Example.png" />
